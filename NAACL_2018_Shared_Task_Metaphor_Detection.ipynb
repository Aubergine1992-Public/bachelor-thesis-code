{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAACL 2018 Shared Task - Metaphor Detection\n",
    "\n",
    "Add description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "- Facebook FastText Embeddings for English\n",
    "- https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "## Preflight Checks\n",
    "\n",
    "- Installed requirements.txt\n",
    "- (optional) Download vuamc.zip http://ota.ahds.ac.uk/headers/2541.xml\n",
    "\n",
    "https://github.com/EducationalTestingService/metaphor/tree/master/NAACL-FLP-shared-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import corpus\n",
    "import evaluate\n",
    "import features\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, Input, Masking, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as kerasbackend\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for VUAMC CSV files and generate if necessary\n",
    "\n",
    "if not os.path.exists('source/vuamc_corpus_test.csv') and not os.path.exists('source/vuamc_corpus_train.csv'):\n",
    "    print('VUAMC training and test data not found. Generating...')\n",
    "    # utils.download_vuamc_xml()\n",
    "    # utils.generate_vuamc_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and validated training corpus\n",
      "Loaded and validated test corpus\n"
     ]
    }
   ],
   "source": [
    "# Load Train Corpus from CSV\n",
    "c_train = corpus.VUAMC('source/vuamc_corpus_train.csv', 'source/verb_tokens_train_gold_labels.csv')\n",
    "c_train.validate_corpus()\n",
    "print('Loaded and validated training corpus')\n",
    "\n",
    "# Load Test Corpus from CSV\n",
    "c_test = corpus.VUAMC('source/vuamc_corpus_test.csv', 'source/verb_tokens_test.csv', mode='test')\n",
    "c_test.validate_corpus()\n",
    "print('Loaded and validated test corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of metaphor tokens: 3\n",
      "Percentage of non-metaphor tokens: 97\n",
      "Ratio: 1:32\n"
     ]
    }
   ],
   "source": [
    "# Shows that we got imbalanced classes in the training data\n",
    "number_of_all_labels = len(c_train.label_list)\n",
    "count_of_label_classes = collections.Counter(c_train.label_list)\n",
    "\n",
    "percentage_of_non_metaphor_tokens = round(count_of_label_classes[0] / number_of_all_labels * 100)\n",
    "percentage_of_metaphor_tokens = round(count_of_label_classes[1] / number_of_all_labels * 100)\n",
    "ratio = utils.simplify_ratio(percentage_of_non_metaphor_tokens, percentage_of_metaphor_tokens)\n",
    "assert(percentage_of_non_metaphor_tokens + percentage_of_metaphor_tokens == 100)\n",
    "\n",
    "print('Percentage of metaphor tokens: {}'.format(percentage_of_metaphor_tokens))\n",
    "print('Percentage of non-metaphor tokens: {}'.format(percentage_of_non_metaphor_tokens))\n",
    "print('Ratio: {}:{}'.format(ratio[0], ratio[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 300\n",
    "KFOLD_SPLIT = 5\n",
    "KERAS_OPTIMIZER = 'rmsprop'\n",
    "KERAS_METRICS = [utils.f1]\n",
    "KERAS_EPOCHS = 1\n",
    "KERAS_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7873/7873 [00:01<00:00, 7172.75it/s]\n",
      "100%|██████████| 2694/2694 [00:00<00:00, 9546.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Word Embeddings\n"
     ]
    }
   ],
   "source": [
    "# embeddings = features.Word2Vec()\n",
    "embeddings = features.DummyEmbeddings(EMBEDDING_DIM)\n",
    "x, y = features.generate_input_and_labels(c_train.sentences, Vectors=embeddings)\n",
    "x_test, y_test = features.generate_input_and_labels(c_test.sentences, Vectors=embeddings)\n",
    "\n",
    "# Free up some memory\n",
    "del embeddings\n",
    "print('Deleted Word Embeddings')\n",
    "\n",
    "# Input data and categorical labels\n",
    "x_input = x\n",
    "y_labels = to_categorical(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_weights: (1, 32)\n"
     ]
    }
   ],
   "source": [
    "# Generate loss_weight, since out dataset contains 97% non-metaphor tokens\n",
    "KERAS_LOSS = utils.weighted_categorical_crossentropy(ratio)\n",
    "print('loss_weights: {}'.format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "masking_3 (Masking)          (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 50, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 50, 2)             402       \n",
      "=================================================================\n",
      "Total params: 321,202\n",
      "Trainable params: 321,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and compile model\n",
    "inputs = Input(shape=(MAX_SENTENCE_LENGTH, EMBEDDING_DIM))\n",
    "model = Masking(mask_value=[-1] * EMBEDDING_DIM)(inputs)\n",
    "model = Bidirectional(LSTM(100, return_sequences=True, dropout=0, recurrent_dropout=0.25))(model)\n",
    "outputs = TimeDistributed(Dense(2, activation='softmax'))(model)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=KERAS_OPTIMIZER, loss=KERAS_LOSS, metrics=KERAS_METRICS)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6298 samples, validate on 1575 samples\n",
      "Epoch 1/1\n",
      "6298/6298 [==============================] - 19s 3ms/step - loss: 0.7392 - f1: 0.8019 - val_loss: 0.5216 - val_f1: 0.7164\n",
      "1575/1575 [==============================] - 2s 1ms/step\n",
      "Test score: 52.16%\n",
      "Test accuracy: 7163.81%\n",
      "Train on 6298 samples, validate on 1575 samples\n",
      "Epoch 1/1\n",
      "6298/6298 [==============================] - 18s 3ms/step - loss: 0.5232 - f1: 0.7900 - val_loss: 0.5382 - val_f1: 0.6691\n",
      "1575/1575 [==============================] - 2s 1ms/step\n",
      "Test score: 53.82%\n",
      "Test accuracy: 6691.30%\n",
      "Train on 6298 samples, validate on 1575 samples\n",
      "Epoch 1/1\n",
      "6298/6298 [==============================] - 18s 3ms/step - loss: 0.5229 - f1: 0.7807 - val_loss: 0.5025 - val_f1: 0.7044\n",
      "1575/1575 [==============================] - 2s 1ms/step\n",
      "Test score: 50.25%\n",
      "Test accuracy: 7044.19%\n",
      "Train on 6299 samples, validate on 1574 samples\n",
      "Epoch 1/1\n",
      "6299/6299 [==============================] - 18s 3ms/step - loss: 0.5193 - f1: 0.7930 - val_loss: 0.5073 - val_f1: 0.7919\n",
      "1574/1574 [==============================] - 2s 1ms/step\n",
      "Test score: 50.73%\n",
      "Test accuracy: 7919.19%\n",
      "Train on 6299 samples, validate on 1574 samples\n",
      "Epoch 1/1\n",
      "6299/6299 [==============================] - 18s 3ms/step - loss: 0.5124 - f1: 0.8009 - val_loss: 0.5237 - val_f1: 0.8141\n",
      "1574/1574 [==============================] - 2s 1ms/step\n",
      "Test score: 52.37%\n",
      "Test accuracy: 8140.66%\n"
     ]
    }
   ],
   "source": [
    "# Generate Training and Validation split\n",
    "kfold = KFold(n_splits=KFOLD_SPLIT, shuffle=True, random_state=1337)\n",
    "for train, test in kfold.split(x_input, y_labels):\n",
    "    x_train = x_input[train]\n",
    "    x_val = x_input[test]\n",
    "    y_train = y_labels[train]\n",
    "    y_val = y_labels[test]\n",
    "\n",
    "    # Fit the model for each split\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=KERAS_BATCH_SIZE,\n",
    "              epochs=KERAS_EPOCHS,\n",
    "              validation_data=(x_val, y_val))\n",
    "\n",
    "    scores = model.evaluate(x_val, y_val)\n",
    "    print('Test score: {:.2%}'.format(scores[0]))\n",
    "    print('Test accuracy: {:.2%}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(precision=0.28904249871991805, recall=0.6846573681018799, f1=0.40648064806480644)\n"
     ]
    }
   ],
   "source": [
    "# Generate list of label predictions for each sentence\n",
    "float_predictions = model.predict(x_test, batch_size=KERAS_BATCH_SIZE)\n",
    "binary_predictions = kerasbackend.argmax(float_predictions)\n",
    "label_predictions = kerasbackend.eval(binary_predictions)\n",
    "\n",
    "# Write prediction to CSV file\n",
    "predictions_file = 'predictions.csv'\n",
    "standard_file = 'source/verb_tokens_test_gold_labels.csv'\n",
    "\n",
    "rows = evaluate.corpus_evaluation(c_test, label_predictions, MAX_SENTENCE_LENGTH)\n",
    "evaluate.csv_evalutation(rows, predictions_file)\n",
    "results = evaluate.precision_recall_f1(predictions_file, standard_file)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Loss",
         "type": "scatter",
         "uid": "8c737d78-b1ff-11e8-8278-94b86d86a98e",
         "y": [
          0.5124241655630656
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Categorical Accuracy",
         "type": "scatter",
         "uid": "8c737d79-b1ff-11e8-8278-94b86d86a98e",
         "y": [
          0.8009239386179879
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Validation Loss",
         "type": "scatter",
         "uid": "8c737d7a-b1ff-11e8-8278-94b86d86a98e",
         "y": [
          0.5236536959680851
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Validation Categorical Accuracy",
         "type": "scatter",
         "uid": "8c737d7b-b1ff-11e8-8278-94b86d86a98e",
         "y": [
          0.8140660323666497
         ]
        }
       ],
       "layout": {
        "title": "Training History",
        "xaxis": {
         "title": "Epoch"
        },
        "yaxis": {
         "title": "Value"
        }
       }
      },
      "text/html": [
       "<div id=\"a319d61b-a202-4acb-a0ea-e381c8c7e966\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a319d61b-a202-4acb-a0ea-e381c8c7e966\", [{\"mode\": \"lines+markers\", \"name\": \"Loss\", \"y\": [0.5124241655630656], \"type\": \"scatter\", \"uid\": \"8c737d78-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Categorical Accuracy\", \"y\": [0.8009239386179879], \"type\": \"scatter\", \"uid\": \"8c737d79-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Loss\", \"y\": [0.5236536959680851], \"type\": \"scatter\", \"uid\": \"8c737d7a-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Categorical Accuracy\", \"y\": [0.8140660323666497], \"type\": \"scatter\", \"uid\": \"8c737d7b-b1ff-11e8-8278-94b86d86a98e\"}], {\"title\": \"Training History\", \"xaxis\": {\"title\": \"Epoch\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a319d61b-a202-4acb-a0ea-e381c8c7e966\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a319d61b-a202-4acb-a0ea-e381c8c7e966\", [{\"mode\": \"lines+markers\", \"name\": \"Loss\", \"y\": [0.5124241655630656], \"type\": \"scatter\", \"uid\": \"8c737d78-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Categorical Accuracy\", \"y\": [0.8009239386179879], \"type\": \"scatter\", \"uid\": \"8c737d79-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Loss\", \"y\": [0.5236536959680851], \"type\": \"scatter\", \"uid\": \"8c737d7a-b1ff-11e8-8278-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Categorical Accuracy\", \"y\": [0.8140660323666497], \"type\": \"scatter\", \"uid\": \"8c737d7b-b1ff-11e8-8278-94b86d86a98e\"}], {\"title\": \"Training History\", \"xaxis\": {\"title\": \"Epoch\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly \n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "loss_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['loss'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Loss'\n",
    ")\n",
    "\n",
    "val_loss_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['val_loss'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "acc_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['f1'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Categorical Accuracy'\n",
    ")\n",
    "\n",
    "val_acc_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['val_f1'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Validation Categorical Accuracy'\n",
    ")\n",
    "\n",
    "layout = plotly.graph_objs.Layout(title=\"Training History\",\n",
    "                yaxis=dict(title='Value'),\n",
    "                xaxis=dict(title='Epoch'))\n",
    "\n",
    "data = [loss_p, acc_p, val_loss_p, val_acc_p]\n",
    "fig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename='jupyter-train-history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
