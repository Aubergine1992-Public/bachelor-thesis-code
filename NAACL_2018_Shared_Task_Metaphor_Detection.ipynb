{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAACL 2018 Shared Task - Metaphor Detection\n",
    "\n",
    "Add description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "- Facebook FastText Embeddings for English\n",
    "- https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "## Preflight Checks\n",
    "\n",
    "- Installed requirements.txt\n",
    "- (optional) Download vuamc.zip http://ota.ahds.ac.uk/headers/2541.xml\n",
    "\n",
    "https://github.com/EducationalTestingService/metaphor/tree/master/NAACL-FLP-shared-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for dependencies\n",
    "import utils\n",
    "import corpus\n",
    "import evaluate\n",
    "import features\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, Input, Masking, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as kerasbackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for VUAMC CSV files and generate if necessary\n",
    "\n",
    "if not os.path.exists('source/vuamc_corpus_test.csv') and not os.path.exists('source/vuamc_corpus_train.csv'):\n",
    "    print('VUAMC training and test data not found. Generating...')\n",
    "    # utils.download_vuamc_xml()\n",
    "    # utils.generate_vuamc_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and validated training corpus\n",
      "Loaded and validated test corpus\n"
     ]
    }
   ],
   "source": [
    "# Load Train Corpus from CSV\n",
    "c_train = corpus.VUAMC('source/vuamc_corpus_train.csv', 'source/verb_tokens_train_gold_labels.csv')\n",
    "c_train.validate_corpus()\n",
    "print('Loaded and validated training corpus')\n",
    "\n",
    "# Load Test Corpus from CSV\n",
    "c_test = corpus.VUAMC('source/vuamc_corpus_test.csv', 'source/verb_tokens_test.csv', mode='test')\n",
    "c_test.validate_corpus()\n",
    "print('Loaded and validated test corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of metaphor tokens: 3\n",
      "Percentage of non-metaphor tokens: 97\n",
      "Ratio: 1:32\n"
     ]
    }
   ],
   "source": [
    "# Shows that we got imbalanced classes in the training data\n",
    "number_of_all_labels = len(c_train.label_list)\n",
    "count_of_label_classes = collections.Counter(c_train.label_list)\n",
    "\n",
    "percentage_of_non_metaphor_tokens = round(count_of_label_classes[0] / number_of_all_labels * 100)\n",
    "percentage_of_metaphor_tokens = round(count_of_label_classes[1] / number_of_all_labels * 100)\n",
    "ratio = utils.simplify_ratio(percentage_of_non_metaphor_tokens, percentage_of_metaphor_tokens)\n",
    "assert(percentage_of_non_metaphor_tokens + percentage_of_metaphor_tokens == 100)\n",
    "\n",
    "print('Percentage of metaphor tokens: {}'.format(percentage_of_metaphor_tokens))\n",
    "print('Percentage of non-metaphor tokens: {}'.format(percentage_of_non_metaphor_tokens))\n",
    "print('Ratio: {}:{}'.format(ratio[0], ratio[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 300\n",
    "KERAS_OPTIMIZER = 'rmsprop'\n",
    "KERAS_METRICS = ['categorical_accuracy']\n",
    "KERAS_EPOCHS = 5\n",
    "KERAS_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Word Embeddings\n"
     ]
    }
   ],
   "source": [
    "# embeddings = features.Word2Vec()\n",
    "embeddings = features.DummyEmbeddings(EMBEDDING_DIM)\n",
    "x, y = features.generate_input_and_labels(c_train.sentences, Vectors=embeddings)\n",
    "x_test, y_test = features.generate_input_and_labels(c_test.sentences, Vectors=embeddings)\n",
    "\n",
    "# Free up some memory\n",
    "del embeddings\n",
    "print('Deleted Word Embeddings')\n",
    "\n",
    "# Input data and categorical labels\n",
    "x_input = x\n",
    "y_labels = to_categorical(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Data tensor: (6299, 50, 300)\n",
      "Shape of Train Labels tensor: (6299, 50, 2)\n",
      "Shape of Validation Data tensor: (1574, 50, 300)\n",
      "Shape of validation Labels tensor: (1574, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate Training and Validation split\n",
    "indices = numpy.arange(x_input.shape[0])\n",
    "numpy.random.shuffle(indices)\n",
    "data = x_input[indices]\n",
    "labels = y_labels[indices]\n",
    "num_validation_samples = int(0.2 * x_input.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n",
    "print('Shape of Train Data tensor:', x_train.shape)\n",
    "print('Shape of Train Labels tensor:', y_train.shape)\n",
    "print('Shape of Validation Data tensor:', x_val.shape)\n",
    "print('Shape of validation Labels tensor:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_weights 1 : 32\n"
     ]
    }
   ],
   "source": [
    "# Generate loss_weight, since out dataset contains 97% non-metaphor tokens\n",
    "# TODO: calculate that shice\n",
    "loss_weight = 32\n",
    "# KERAS_LOSS = 'categorical_crossentropy'\n",
    "KERAS_LOSS = utils.weighted_categorical_crossentropy([1, loss_weight])\n",
    "print('loss_weights 1 : {}'.format(loss_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6299 samples, validate on 1574 samples\n",
      "Epoch 1/5\n",
      "6299/6299 [==============================] - 20s 3ms/step - loss: 0.7309 - categorical_accuracy: 0.7953 - val_loss: 0.5206 - val_categorical_accuracy: 0.7759\n",
      "Epoch 2/5\n",
      "6299/6299 [==============================] - 18s 3ms/step - loss: 0.5218 - categorical_accuracy: 0.7942 - val_loss: 0.5231 - val_categorical_accuracy: 0.8839\n",
      "Epoch 3/5\n",
      "6299/6299 [==============================] - 18s 3ms/step - loss: 0.5173 - categorical_accuracy: 0.7976 - val_loss: 0.5203 - val_categorical_accuracy: 0.7682\n",
      "Epoch 4/5\n",
      "6299/6299 [==============================] - 18s 3ms/step - loss: 0.5133 - categorical_accuracy: 0.8052 - val_loss: 0.5235 - val_categorical_accuracy: 0.8777\n",
      "Epoch 5/5\n",
      "6299/6299 [==============================] - 19s 3ms/step - loss: 0.5104 - categorical_accuracy: 0.8088 - val_loss: 0.5250 - val_categorical_accuracy: 0.8190\n",
      "1574/1574 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create and compile model\n",
    "inputs = Input(shape=(MAX_SENTENCE_LENGTH, EMBEDDING_DIM))\n",
    "model = Masking(mask_value=[-1] * EMBEDDING_DIM)(inputs)\n",
    "model = Bidirectional(LSTM(100, return_sequences=True, dropout=0, recurrent_dropout=0.25))(model)\n",
    "outputs = TimeDistributed(Dense(2, activation='softmax'))(model)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=KERAS_OPTIMIZER, loss=KERAS_LOSS, metrics=KERAS_METRICS)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, batch_size=KERAS_BATCH_SIZE, epochs=KERAS_EPOCHS, validation_data=(x_val, y_val))\n",
    "scores = model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(precision=0.6688902365069739, recall=0.6688902365069739, f1=0.6688902365069739)\n"
     ]
    }
   ],
   "source": [
    "# Generate list of label predictions for each sentence\n",
    "float_predictions = model.predict(x_test, batch_size=KERAS_BATCH_SIZE)\n",
    "binary_predictions = kerasbackend.argmax(float_predictions)\n",
    "label_predictions = kerasbackend.eval(binary_predictions)\n",
    "\n",
    "# Write prediction to CSV file\n",
    "predictions_file = 'predictions.csv'\n",
    "standard_file = 'source/verb_tokens_test_gold_labels.csv'\n",
    "\n",
    "rows = evaluate.corpus_evaluation(c_test, label_predictions, MAX_SENTENCE_LENGTH)\n",
    "evaluate.csv_evalutation(rows, predictions_file)\n",
    "results = evaluate.precision_recall_f1(predictions_file, standard_file)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Loss",
         "type": "scatter",
         "uid": "985ee196-b122-11e8-8955-94b86d86a98e",
         "y": [
          0.7308631343280613,
          0.5217532383759715,
          0.5173172974448333,
          0.5132531015707171,
          0.5103549715790943
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Categorical Accuracy",
         "type": "scatter",
         "uid": "985ee197-b122-11e8-8955-94b86d86a98e",
         "y": [
          0.7952976654798081,
          0.7941609771691877,
          0.7975678673470318,
          0.8051690732435416,
          0.808798222782915
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Validation Loss",
         "type": "scatter",
         "uid": "985ee198-b122-11e8-8955-94b86d86a98e",
         "y": [
          0.5206219879614504,
          0.5231086462546789,
          0.520345386813526,
          0.5235012822714664,
          0.524987906634126
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Validation Categorical Accuracy",
         "type": "scatter",
         "uid": "985ee199-b122-11e8-8955-94b86d86a98e",
         "y": [
          0.775946636060596,
          0.8838500653924906,
          0.7682337999495346,
          0.8776620081146609,
          0.8189707768766217
         ]
        }
       ],
       "layout": {
        "title": "Training History",
        "xaxis": {
         "title": "Epoch"
        },
        "yaxis": {
         "title": "Value"
        }
       }
      },
      "text/html": [
       "<div id=\"1f93ee8b-b5ec-4477-82b8-c69ad904731a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1f93ee8b-b5ec-4477-82b8-c69ad904731a\", [{\"mode\": \"lines+markers\", \"name\": \"Loss\", \"y\": [0.7308631343280613, 0.5217532383759715, 0.5173172974448333, 0.5132531015707171, 0.5103549715790943], \"type\": \"scatter\", \"uid\": \"985ee196-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Categorical Accuracy\", \"y\": [0.7952976654798081, 0.7941609771691877, 0.7975678673470318, 0.8051690732435416, 0.808798222782915], \"type\": \"scatter\", \"uid\": \"985ee197-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Loss\", \"y\": [0.5206219879614504, 0.5231086462546789, 0.520345386813526, 0.5235012822714664, 0.524987906634126], \"type\": \"scatter\", \"uid\": \"985ee198-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Categorical Accuracy\", \"y\": [0.775946636060596, 0.8838500653924906, 0.7682337999495346, 0.8776620081146609, 0.8189707768766217], \"type\": \"scatter\", \"uid\": \"985ee199-b122-11e8-8955-94b86d86a98e\"}], {\"title\": \"Training History\", \"xaxis\": {\"title\": \"Epoch\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1f93ee8b-b5ec-4477-82b8-c69ad904731a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1f93ee8b-b5ec-4477-82b8-c69ad904731a\", [{\"mode\": \"lines+markers\", \"name\": \"Loss\", \"y\": [0.7308631343280613, 0.5217532383759715, 0.5173172974448333, 0.5132531015707171, 0.5103549715790943], \"type\": \"scatter\", \"uid\": \"985ee196-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Categorical Accuracy\", \"y\": [0.7952976654798081, 0.7941609771691877, 0.7975678673470318, 0.8051690732435416, 0.808798222782915], \"type\": \"scatter\", \"uid\": \"985ee197-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Loss\", \"y\": [0.5206219879614504, 0.5231086462546789, 0.520345386813526, 0.5235012822714664, 0.524987906634126], \"type\": \"scatter\", \"uid\": \"985ee198-b122-11e8-8955-94b86d86a98e\"}, {\"mode\": \"lines+markers\", \"name\": \"Validation Categorical Accuracy\", \"y\": [0.775946636060596, 0.8838500653924906, 0.7682337999495346, 0.8776620081146609, 0.8189707768766217], \"type\": \"scatter\", \"uid\": \"985ee199-b122-11e8-8955-94b86d86a98e\"}], {\"title\": \"Training History\", \"xaxis\": {\"title\": \"Epoch\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly \n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "loss_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['loss'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Loss'\n",
    ")\n",
    "\n",
    "val_loss_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['val_loss'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "acc_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['categorical_accuracy'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Categorical Accuracy'\n",
    ")\n",
    "\n",
    "val_acc_p = plotly.graph_objs.Scatter(\n",
    "    y = model.history.history['val_categorical_accuracy'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Validation Categorical Accuracy'\n",
    ")\n",
    "\n",
    "layout = plotly.graph_objs.Layout(title=\"Training History\",\n",
    "                yaxis=dict(title='Value'),\n",
    "                xaxis=dict(title='Epoch'))\n",
    "\n",
    "data = [loss_p, acc_p, val_loss_p, val_acc_p]\n",
    "fig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename='jupyter-train-history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
